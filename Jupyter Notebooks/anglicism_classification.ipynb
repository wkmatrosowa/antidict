{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы использовать модель, нужно скачать [архив](https://rusvectores.org/static/models/rusvectores4/fasttext/araneum_none_fasttextcbow_300_5_2018.tgz) и распаковать его."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('better_words_2.csv', encoding='utf-8', sep='\\t', names=['word', 'info', 'modified'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.KeyedVectors.load(\"araneum_none_fasttextcbow_300_5_2018.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('раскритиковывать', 0.6009185314178467),\n",
       " ('критиковать', 0.4883984327316284),\n",
       " ('критика', 0.4764508605003357),\n",
       " ('покритиковать', 0.47199517488479614),\n",
       " ('высказывание', 0.46378931403160095),\n",
       " ('интерпретировать', 0.45879337191581726),\n",
       " ('критик', 0.45685070753097534),\n",
       " ('самокритика', 0.4509151577949524),\n",
       " ('ритик', 0.45008182525634766),\n",
       " ('телекритика', 0.4466124176979065)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('раскритиковать')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('forms.txt') as file: # словарь словоформ\n",
    "#     forms = file.readlines()\n",
    "# forms = [word.strip('\\\"»«\\n)(') for word in forms]\n",
    "# forms = [word.lower() for word in forms if word]\n",
    "\n",
    "# forms = pd.Series(forms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forms.to_csv('forms.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('forms.txt') as file: # словарь словоформ\n",
    "    forms = file.readlines()\n",
    "forms = [word.strip('\\\"»«\\n)(') for word in forms]\n",
    "forms = [word.lower() for word in forms if word]\n",
    "\n",
    "with open('slovar_edited.csv', encoding='utf-8') as file: # словарь англицизмов\n",
    "    slovar = file.readlines()\n",
    "slovar = [word.strip('\\\"»«\\n)(') for word in slovar]\n",
    "slovar = [word.lower() for word in slovar if len(word) > 1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные очень несбалансированные, поэтому сделаем выборку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2334516, 16107)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(forms), len(slovar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также отдельно отложим данные для валидации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "forms = pd.DataFrame({'word': forms, 'label': 0}).sample(60000)\n",
    "forms_train = forms.head(50000)\n",
    "forms_valid = forms.tail(10000)\n",
    "slovar = pd.DataFrame({'word': slovar, 'label': 1}).sample(frac=1)\n",
    "slovar_train = slovar.head(13107)\n",
    "slovar_valid = slovar.tail(3000)\n",
    "training = pd.concat([forms_train, slovar_train])\n",
    "validation = pd.concat([forms_valid, slovar_valid]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "training['model'] = training.word.apply(lambda x: model[x])\n",
    "validation['model'] = validation.word.apply(lambda x: model[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.vstack(training.model.values)\n",
    "y = training['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63107, 300)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_1 = LogisticRegression(random_state=0, n_jobs=-1, C=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=4, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=-1, penalty='l2', random_state=0,\n",
       "                   solver='lbfgs', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_data(num, clf):\n",
    "    for word in data.sample(num).modified.values:\n",
    "        res = clf.predict(model[word].reshape(1, -1))\n",
    "        if res[0] == 1:\n",
    "            print(f\"{word}: {res}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "эксодарлинг: [1]\n",
      "цемус: [1]\n",
      "сигулдской: [1]\n",
      "эбсолют: [1]\n",
      "хурум: [1]\n",
      "эвергрины: [1]\n",
      "джонхерт: [1]\n",
      "эмплом: [1]\n",
      "бентаму: [1]\n",
      "шаолин: [1]\n",
      "пейджик: [1]\n",
      "тьса: [1]\n",
      "хьюзмолер: [1]\n",
      "уитстон: [1]\n",
      "хайвелд: [1]\n",
      "дигов: [1]\n",
      "нихон: [1]\n"
     ]
    }
   ],
   "source": [
    "sample_data(200, clf_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8031142781736607"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf_1.predict(X_test)\n",
    "f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>label</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1449</th>\n",
       "      <td>бифуркация</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.06252903, -0.02508882, -0.023080893, -0.080...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4696</th>\n",
       "      <td>имиджмейкинг</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.014999646, -0.044523843, 0.07029855, 0.0075...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8132</th>\n",
       "      <td>необычный</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.07833143, -0.10165572, 0.06670411, 0.00448...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14272</th>\n",
       "      <td>фреймлайт</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.003905304, -0.026356818, -0.001231998, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3294</th>\n",
       "      <td>гросс</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.04398974, 0.0130719915, 0.016659278, 0.0120...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               word  label                                              model\n",
       "1449     бифуркация      1  [0.06252903, -0.02508882, -0.023080893, -0.080...\n",
       "4696   имиджмейкинг      1  [0.014999646, -0.044523843, 0.07029855, 0.0075...\n",
       "8132      необычный      1  [-0.07833143, -0.10165572, 0.06670411, 0.00448...\n",
       "14272     фреймлайт      1  [0.003905304, -0.026356818, -0.001231998, -0.0...\n",
       "3294          гросс      1  [0.04398974, 0.0130719915, 0.016659278, 0.0120..."
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation.loc[validation.label == 1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_word(word, classifier):\n",
    "    return classifier.predict(model[word].reshape(1, -1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation['prediction'] = validation.word.apply(predict_word, args=(clf_1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8132654983983418"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(validation.label.values, validation.prediction.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGDClassifier(class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight='balanced',\n",
       "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
       "              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "              power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
       "              validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation['prediction'] = validation.word.apply(predict_word, args=(sgd, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ритмовай: [1]\n",
      "ринмо: [1]\n",
      "нипи: [1]\n",
      "свм: [1]\n",
      "жут: [1]\n",
      "симсоноф: [1]\n",
      "фрайята: [1]\n",
      "баретер: [1]\n",
      "вайть: [1]\n",
      "литчман: [1]\n",
      "плэнинг: [1]\n",
      "манеджемент: [1]\n",
      "сифуэнтесом: [1]\n",
      "еврохолуев: [1]\n",
      "босовой: [1]\n",
      "презентосал: [1]\n",
      "фотоприкол: [1]\n",
      "бобато: [1]\n",
      "альхага: [1]\n",
      "скайпику: [1]\n",
      "синатрыча: [1]\n",
      "диайвайщика: [1]\n",
      "кенас: [1]\n",
      "криптосистемой: [1]\n",
      "алкобиологи: [1]\n",
      "читлом: [1]\n",
      "арнего: [1]\n",
      "мегакризисом: [1]\n",
      "камандуе: [1]\n",
      "сиаму: [1]\n",
      "пухкете: [1]\n",
      "бимиш: [1]\n",
      "логистиктрансэкспрес: [1]\n",
      "пауэле: [1]\n"
     ]
    }
   ],
   "source": [
    "sample_data(200, sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8470781893004116"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(validation.label.values, validation.prediction.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_2 = MLPClassifier(max_iter=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 29s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_fun=15000, max_iter=300,\n",
       "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
       "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "clf_2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation['prediction'] = validation.word.apply(predict_word, args=(clf_2, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8519462859085501"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(validation.label.values, validation.prediction.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "эйлатскую: [1]\n",
      "сутинен: [1]\n",
      "кать: [1]\n",
      "сейачс: [1]\n",
      "раджай: [1]\n",
      "антияхвизм: [1]\n",
      "афроамериканопопыми: [1]\n",
      "офигительный: [1]\n",
      "бодоне: [1]\n",
      "унгард: [1]\n",
      "спэшиэл: [1]\n",
      "псевдочастники: [1]\n",
      "фьюитьнулась: [1]\n",
      "вэйдерам: [1]\n",
      "чстота: [1]\n",
      "тамуридис: [1]\n",
      "неймингу: [1]\n",
      "хиповата: [1]\n",
      "линкбейтинга: [1]\n",
      "фури: [1]\n",
      "тейа: [1]\n",
      "ганен: [1]\n",
      "свинго: [1]\n",
      "фэйрбразер: [1]\n",
      "онтакт: [1]\n",
      "нифъаль: [1]\n",
      "сиэн: [1]\n",
      "нол: [1]\n",
      "шутерну: [1]\n",
      "макгоуну: [1]\n",
      "роканрол: [1]\n",
      "амеркианцы: [1]\n",
      "котманду: [1]\n",
      "аруактар: [1]\n",
      "мейдфорвардера: [1]\n",
      "сильверкрос: [1]\n",
      "френды: [1]\n",
      "уолдману: [1]\n",
      "максимаркет: [1]\n",
      "фебруаре: [1]\n"
     ]
    }
   ],
   "source": [
    "sample_data(200, clf_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_3 = LinearSVC(class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation['prediction'] = validation.word.apply(predict_word, args=(clf_3, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8470781893004116"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(validation.label.values, validation.prediction.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "украиноцентричные: [1]\n",
      "театър: [1]\n",
      "гинчо: [1]\n",
      "штекно: [1]\n",
      "рамштиайнов: [1]\n",
      "дзун: [1]\n",
      "шлемоподобный: [1]\n",
      "фамлией: [1]\n",
      "паркують: [1]\n",
      "берсеркоподобная: [1]\n",
      "постопив: [1]\n",
      "мэнамской: [1]\n",
      "амадан: [1]\n",
      "мицубиську: [1]\n",
      "надувака: [1]\n",
      "интелектуальными: [1]\n",
      "меркаванем: [1]\n",
      "экуной: [1]\n",
      "бокены: [1]\n",
      "уфал: [1]\n",
      "евродэнсом: [1]\n",
      "блоджы: [1]\n",
      "рашнбизнес: [1]\n",
      "тренхарда: [1]\n",
      "авиатура: [1]\n",
      "френджу: [1]\n",
      "райн: [1]\n",
      "пингарея: [1]\n",
      "волтер: [1]\n",
      "имьютабл: [1]\n",
      "шиладжит: [1]\n",
      "актерство: [1]\n",
      "вэбсайта: [1]\n",
      "бихевиористкие: [1]\n",
      "гиперкапния: [1]\n",
      "хелмеру: [1]\n",
      "вильяфафила: [1]\n",
      "пактеик: [1]\n"
     ]
    }
   ],
   "source": [
    "sample_data(200, clf_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.svm import OneClassSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index = []\n",
    "# word = []\n",
    "\n",
    "# for word in data.modified:\n",
    "#     res = clf.predict(model[word].reshape(1, -1))\n",
    "#     if res[0] == 1:\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('stand_angl.csv', 'w', encoding='utf-8') as file:\n",
    "#     file.writelines('word\\n')\n",
    "#     for word in data.sample(frac=1).modified.values:\n",
    "#         res = clf.predict(model[word].reshape(1, -1))\n",
    "#         if res[0] == 1:\n",
    "#             line = word + '\\n'\n",
    "#             file.writelines(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('stand_angl_2.csv', 'w', encoding='utf-8') as file:\n",
    "#     file.writelines('word\\n')\n",
    "#     for word in data.sample(frac=1).modified.values:\n",
    "#         res = clf.predict(model[word].reshape(1, -1))\n",
    "#         if res[0] == 1:\n",
    "#             line = word + '\\n'\n",
    "#             file.writelines(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
